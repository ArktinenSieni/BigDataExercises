{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Contents:-\n",
    "1. HDFS setup\n",
    "2. Alluxio(Tachyoon) Setup\n",
    "3. Spark Streaming Basics \n",
    "4. Exercise 2 Solutions\n",
    "\n",
    "\n",
    "## All Hadoop functionalities in pyspark\n",
    "http://spark.apache.org/docs/latest/api/python/search.html?q=Hadoop&check_keywords=yes&area=default\n",
    "    \n",
    "## All functionalities in Scala Spark\n",
    "http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. HDFS \n",
    "\n",
    "__Download__\n",
    "\n",
    "http://hadoop.apache.org/releases.html\n",
    "        \n",
    "Download 2.7.x binary tarball and folow the installation instructions below. (Written on Apr 5 2017)\n",
    "\n",
    "\n",
    "__Steps to installation__\n",
    "    1. Download the tar file and extract it in a directory you wish\n",
    "        tar -xzvf hadoop-2.7.3.tar.gz \n",
    "    2. Now set the following environment variables for hadoop\n",
    "        export HADOOP_INSTALL=/home/hadoop-x.y.z\n",
    "        export PATH=$PATH:$HADOOP_INSTALL/bin\n",
    "    3. Now in a terminal check if the path is set using the following command\n",
    "        hadoop version\n",
    "        If the above command is not working then check your JAVA_HOME settings. \n",
    "References :-\n",
    "http://archive.oreilly.com/pub/a/other-programming/excerpts/hadoop-tdg/installing-apache-hadoop.html\n",
    "\n",
    "\n",
    "__Explore the Hadoop folder:__\n",
    "    1. All scripts to run can be found here - Similar to Spark\n",
    "        /hadoop-2.7.3/sbin\n",
    "    2. Configuration settigns can be found here\n",
    "        /hadoop-2.7.3/etc/hadoop\n",
    "    3. Now change two configuration files, \n",
    "        etc/hadoop/core-site.xml\n",
    "            <configuration>\n",
    "                <property>\n",
    "                    <name>fs.defaultFS</name>\n",
    "                    <value>hdfs://localhost:9000</value>\n",
    "                </property>\n",
    "            </configuration>\n",
    "        etc/hadoop/hdfs-site.xml\n",
    "            <configuration>\n",
    "                <property>\n",
    "                    <name>dfs.replication</name>\n",
    "                    <value>1</value>\n",
    "                </property>\n",
    "            </configuration>\n",
    "    4. Now Format the file system (First time setup only)\n",
    "        bin/hdfs namenode -format\n",
    "    5. Start your HDFS,\n",
    "        sbin/start-dfs.sh\n",
    "    6. By default the NameNode will run in the following address\n",
    "        http://localhost:50070/\n",
    "    Hint: \n",
    "        While starting the server, it will ask for the local host password. If you are using the UKKO, use your ssh key password and not the CS password. \n",
    "    \n",
    "References :\n",
    "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html\n",
    "\n",
    "\n",
    "__Getting Started__\n",
    "https://wiki.apache.org/hadoop/GettingStartedWithHadoop\n",
    "\n",
    "\n",
    "__Steps to creating HDFS:-__\n",
    "    1. Download the and extract the carat csv file to a location\n",
    "    2. Now create a new directory for in hdfs to move the csv file there\n",
    "        hdfs dfs -mkdir /input/\n",
    "    3. Copy the carat CSV file to the new location\n",
    "        hdfs dfs -put /cs/home/user_name/carat/carat-context-factors-percom.csv /input/carat-context-factors-percom.csv\n",
    "    4. Now start your spark shell, and use the following command to load the csv file.\n",
    "        sc.textFile(\"hdfs://localhost:9000/input/carat-context-factors-percom.csv\")\n",
    "    5. After using spark shell, shutdown your HDFS, using the following command\n",
    "        sbin/stop-dfs.sh\n",
    "    6. Check all services are down using the following command,\n",
    "        ps aux | grep namenode\n",
    "    http://stackoverflow.com/questions/28213116/hadoop-copy-a-local-file-system-folder-to-hdfs\n",
    "\n",
    "\n",
    "# Examples\n",
    "\n",
    "http://www.ccs.neu.edu/home/cbw/spark.html\n",
    "\n",
    "http://stackoverflow.com/questions/27478096/cannot-read-a-file-from-hdfs-using-spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Alluxio \n",
    "\n",
    "Not supported in Windows yet\n",
    "\n",
    "__Source Code :__\n",
    "\n",
    "    https://github.com/Alluxio/alluxio\n",
    "        \n",
    "__Website:__\n",
    "    \n",
    "    http://www.alluxio.org/\n",
    "\n",
    "__Official Documentation:__\n",
    "\n",
    "    http://www.alluxio.org/docs/1.4/en/Getting-Started.html\n",
    "\n",
    "\n",
    "__Running Spark on Alluxio__\n",
    "\n",
    "    http://www.alluxio.org/docs/1.4/en/Running-Spark-on-Alluxio.html\n",
    "    \n",
    "## Start from here - Steps to install \n",
    "    http://www.alluxio.org/docs/1.4/en/Getting-Started.html\n",
    "    http://www.alluxio.org/docs/1.4/en/Running-Alluxio-Locally.html\n",
    "    \n",
    "## Connecting to Spark\n",
    "    http://www.alluxio.org/docs/1.4/en/Running-Spark-on-Alluxio.html\n",
    "    http://www.alluxio.org/docs/1.0/en/Running-Spark-on-Alluxio.html\n",
    "    \n",
    "    Remember to set SPARK_CLASSPATH, ALLUXIO_HOME values.\n",
    "    The set the core-site.xml file,\n",
    "        cp core-site.xml.template core-site.xml\n",
    "    \n",
    "    For Example,\n",
    "    Moving a file into alluxio file system(this requires your localhost to be running),\n",
    "    \n",
    "    ./alluxio fs copyFromLocal /Users/mohanprasanth/Documents/alluxio-1.4.0/LICENSE /LICENSE\n",
    "    \n",
    "    Test it suing a Spark example,\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
